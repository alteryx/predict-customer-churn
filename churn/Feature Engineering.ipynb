{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Automated Feature Engineering with Featuretools\n",
    "\n",
    "Automated feature engineering allows us to create hundreds or thousands of relevant features from a relational dataset in a few lines of code that can be re-used across problems. Currently, the only option for automated feature engineering using many related tables is Featuretools, an open-source Python library. \n",
    "\n",
    "In this notebook, we'll work with Featuretools to develop an automated feature engineering workflow for a single partition of the customer churn data. After developing a method that works for one partition, we can take this idea and apply it to many partitions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "N_PARTITIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logs.csv',\n",
       " 'members.csv',\n",
       " 'train.csv',\n",
       " 'cancel_cutoff_times.csv',\n",
       " 'test.csv',\n",
       " 'transactions.csv',\n",
       " 'cutoff_times.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTITION = '500'\n",
    "directory = '/data/churn/partitions/p' + PARTITION\n",
    "\n",
    "import os\n",
    "os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv(f'{directory}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], \n",
    "                      infer_datetime_format = True, \n",
    "                      dtype = {'gender': 'category'})\n",
    "\n",
    "trans = pd.read_csv(f'{directory}/transactions.csv',\n",
    "                   parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                    infer_datetime_format = True)\n",
    "\n",
    "logs = pd.read_csv(f'{directory}/logs.csv', parse_dates = ['date'])\n",
    "cutoff_times = pd.read_csv(f'{directory}/cutoff_times.csv', parse_dates = ['cutoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21987, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_times.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Entities\n",
    "\n",
    "The entityset structure for this problem is fairly simple as there are only three entities.  `members` is the parent with `logs` and `transactions` both children. In both relationships, the parent and child variable is `msno`, the customer id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "es = ft.EntitySet(id = 'customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IPcy704aIqoa4MY5NBAKhVw1qZCWvQcYICBVMufSbcg=</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N7VphdA9MRD/ojyO/jSWydNrQqfZMe2d1eDl5kwB+vg=</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wnOtVWT2Hi28usrU9Yb0JCdl/TGO48HUfJlgehG0kDw=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEIygRcw0Soz4FguDgJQnSrlHoTYHmlvTcoOLB9dF2Y=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q4k48ZA18embL69OlVhGpT/8sB5nhETBpH5B6Ud+JXI=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-08-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  IPcy704aIqoa4MY5NBAKhVw1qZCWvQcYICBVMufSbcg=     5   0    male   \n",
       "1  N7VphdA9MRD/ojyO/jSWydNrQqfZMe2d1eDl5kwB+vg=     5  17  female   \n",
       "2  wnOtVWT2Hi28usrU9Yb0JCdl/TGO48HUfJlgehG0kDw=     1   0     NaN   \n",
       "3  DEIygRcw0Soz4FguDgJQnSrlHoTYHmlvTcoOLB9dF2Y=     1   0     NaN   \n",
       "4  q4k48ZA18embL69OlVhGpT/8sB5nhETBpH5B6Ud+JXI=     1   0     NaN   \n",
       "\n",
       "   registered_via registration_init_time  \n",
       "0               3             2014-11-02  \n",
       "1               4             2016-12-26  \n",
       "2               4             2017-01-20  \n",
       "3               4             2017-01-21  \n",
       "4               4             2016-08-15  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members['msno'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                         index = 'msno', time_index = 'registration_init_time', \n",
    "                         variable_types = {'city': vtypes.Categorical, 'bd': vtypes.Categorical,\n",
    "                                           'registered_via': vtypes.Categorical})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>price_difference</th>\n",
       "      <th>planned_daily_price</th>\n",
       "      <th>daily_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/4OzeklvQKOIr804cYEbcsy4xbpWHQFF40oeMTMuTak=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1lhQM//dvJCyWLTaCw7x+aDrCFNhNk/8QzlMwiRgB4Y=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>4.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bSgrbAUbyZDpkoQgVxeH4dQ7v8yEoucUK0lB0x6F2R0=</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>4.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c3HjpBgEcGfa+mkJVtC47gE2CaW+KTBUxijgvrnBUuY=</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vWLvk74sFSINQPmCbcIMqAh1MDdzxroTKIjaxKWEQHA=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  /4OzeklvQKOIr804cYEbcsy4xbpWHQFF40oeMTMuTak=                 41   \n",
       "1  1lhQM//dvJCyWLTaCw7x+aDrCFNhNk/8QzlMwiRgB4Y=                 41   \n",
       "2  bSgrbAUbyZDpkoQgVxeH4dQ7v8yEoucUK0lB0x6F2R0=                 21   \n",
       "3  c3HjpBgEcGfa+mkJVtC47gE2CaW+KTBUxijgvrnBUuY=                 28   \n",
       "4  vWLvk74sFSINQPmCbcIMqAh1MDdzxroTKIjaxKWEQHA=                 41   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              129                 129              1   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              149                 149              1   \n",
       "3                 30              150                 150              0   \n",
       "4                 30               99                  99              1   \n",
       "\n",
       "  transaction_date membership_expire_date  is_cancel  price_difference  \\\n",
       "0       2016-02-29             2016-03-31          0                 0   \n",
       "1       2015-12-31             2016-01-31          0                 0   \n",
       "2       2015-12-02             2016-01-08          0                 0   \n",
       "3       2016-07-02             2016-08-01          0                 0   \n",
       "4       2016-09-13             2016-10-13          0                 0   \n",
       "\n",
       "   planned_daily_price  daily_price  \n",
       "0             4.300000     4.300000  \n",
       "1             4.966667     4.966667  \n",
       "2             4.966667     4.966667  \n",
       "3             5.000000     5.000000  \n",
       "4             3.300000     3.300000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "    transactions [Rows: 22859, Columns: 13]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                         index = 'transactions_index', make_index = True,\n",
    "                         time_index = 'transaction_date', \n",
    "                         variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                           'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})\n",
    "\n",
    "es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>total</th>\n",
       "      <th>percent_100</th>\n",
       "      <th>percent_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1T6cC9wlTNDxYh+ikIsljHO3LJ62pdNxeo0uC6b9iUk=</td>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>12650.427</td>\n",
       "      <td>74</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.689189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qbj5QJcK+N/z9h4fR82QYmABCS9g3EIbGijYxqOAw3M=</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>10247.052</td>\n",
       "      <td>47</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tk3KXVctKu4yERExEwFvMMOrpU88K083pDNRONhpMzY=</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>4565.533</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q9u6CM2lMNSyc0mHPnH9O/yWvMGqeTcMqBHRnS7s0MI=</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>5523.670</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a/vnjfU45TFglx+JFOPBWQHOaQdEY/lYUw8cxLurbwA=</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>3670.509</td>\n",
       "      <td>18</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno       date  num_25  num_50  \\\n",
       "0  1T6cC9wlTNDxYh+ikIsljHO3LJ62pdNxeo0uC6b9iUk= 2017-03-17      17       1   \n",
       "1  Qbj5QJcK+N/z9h4fR82QYmABCS9g3EIbGijYxqOAw3M= 2017-03-01       4       2   \n",
       "2  tk3KXVctKu4yERExEwFvMMOrpU88K083pDNRONhpMzY= 2017-03-30       0       0   \n",
       "3  q9u6CM2lMNSyc0mHPnH9O/yWvMGqeTcMqBHRnS7s0MI= 2017-03-20       0       0   \n",
       "4  a/vnjfU45TFglx+JFOPBWQHOaQdEY/lYUw8cxLurbwA= 2017-03-10       4       1   \n",
       "\n",
       "   num_75  num_985  num_100  num_unq  total_secs  total  percent_100  \\\n",
       "0       1        0       55       51   12650.427     74     0.743243   \n",
       "1       2        1       38       46   10247.052     47     0.808511   \n",
       "2       0        0       18       18    4565.533     18     1.000000   \n",
       "3       0        0       21       21    5523.670     21     1.000000   \n",
       "4       1        0       12       11    3670.509     18     0.666667   \n",
       "\n",
       "   percent_unique  \n",
       "0        0.689189  \n",
       "1        0.978723  \n",
       "2        1.000000  \n",
       "3        1.000000  \n",
       "4        0.611111  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "logs['percent_unique'] = logs['num_unq'] / logs['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "    transactions [Rows: 22859, Columns: 13]\n",
       "    logs [Rows: 401596, Columns: 13]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting Values\n",
    "\n",
    "In order to create conditional features, we can set interesting values for existing columns in the data. The following code will be used to build features conditional on the value of `is_cancel` and `is_auto_renew` in the transactions data. The primitives used for the conditional features are specified as `where_primitives` in the call to Deep Feature Synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "es['transactions']['is_auto_renew'].interesting_values = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships\n",
    "\n",
    "There are two relationships: one linking `members` to `transactions` and one linking `members` to `logs`. The order for relationships is parent variable, child variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "    transactions [Rows: 22859, Columns: 13]\n",
       "    logs [Rows: 401596, Columns: 13]\n",
       "  Relationships:\n",
       "    transactions.msno -> members.msno\n",
       "    logs.msno -> members.msno"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "\n",
    "es.add_relationships([r_member_transactions, r_member_logs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feature Synthesis\n",
    "\n",
    "With the entities and relationships fully defined, we are ready to run Deep Feature Synthesis (DFS). To start, we'll use the default aggregation and transformation primitives as well as two `where_primitives` and see how many features this generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                      cutoff_time = cutoff_times,\n",
    "                      where_primitives = ['sum', 'mean'],\n",
    "                      max_depth=2, features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will generate 182 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'This will generate {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Primitives \n",
    "\n",
    "Now we'll do a call to `ft.dfs` specifying the primitives to use. Often, these will depend on the problem and can involve domain knowledge. We can also build our own custom primitives to use on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trend</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the slope of the linear trend of va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>median</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the median value of any feature with wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sum</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Sums elements of a numeric or boolean feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_since_last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Time since last related instance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_time_between</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average time between consecutive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Test if all values are 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n_most_common</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the N most common elements in a categori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the number of 'True' values in a boolean.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>any</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Test if any value is 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mode</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the most common element in a categorical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>skew</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the skewness of a data set.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num_unique</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Returns the number of unique categorical varia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>min</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the minimum non-null value of a numeric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Returns the last value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average value of a numeric feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>percent_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the percent of 'True' values in a boolea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the maximum non-null value of a numeric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>std</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the standard deviation of a numeric feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>count</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Counts the number of non null values.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name         type  \\\n",
       "0              trend  aggregation   \n",
       "1             median  aggregation   \n",
       "2                sum  aggregation   \n",
       "3    time_since_last  aggregation   \n",
       "4   avg_time_between  aggregation   \n",
       "5                all  aggregation   \n",
       "6      n_most_common  aggregation   \n",
       "7           num_true  aggregation   \n",
       "8                any  aggregation   \n",
       "9               mode  aggregation   \n",
       "10              skew  aggregation   \n",
       "11        num_unique  aggregation   \n",
       "12               min  aggregation   \n",
       "13              last  aggregation   \n",
       "14              mean  aggregation   \n",
       "15      percent_true  aggregation   \n",
       "16               max  aggregation   \n",
       "17               std  aggregation   \n",
       "18             count  aggregation   \n",
       "\n",
       "                                          description  \n",
       "0   Calculates the slope of the linear trend of va...  \n",
       "1   Finds the median value of any feature with wel...  \n",
       "2      Sums elements of a numeric or boolean feature.  \n",
       "3                   Time since last related instance.  \n",
       "4   Computes the average time between consecutive ...  \n",
       "5                      Test if all values are 'True'.  \n",
       "6   Finds the N most common elements in a categori...  \n",
       "7     Finds the number of 'True' values in a boolean.  \n",
       "8                        Test if any value is 'True'.  \n",
       "9   Finds the most common element in a categorical...  \n",
       "10               Computes the skewness of a data set.  \n",
       "11  Returns the number of unique categorical varia...  \n",
       "12  Finds the minimum non-null value of a numeric ...  \n",
       "13                            Returns the last value.  \n",
       "14   Computes the average value of a numeric feature.  \n",
       "15  Finds the percent of 'True' values in a boolea...  \n",
       "16  Finds the maximum non-null value of a numeric ...  \n",
       "17  Finds the standard deviation of a numeric feat...  \n",
       "18              Counts the number of non null values.  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_p = ft.list_primitives()\n",
    "trans_p = all_p.loc[all_p['type'] == 'transform'].copy()\n",
    "agg_p = all_p.loc[all_p['type'] == 'aggregation'].copy()\n",
    "\n",
    "pd.options.display.max_rows = 50\n",
    "agg_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_primitives = ['sum', 'time_since_last', 'avg_time_between', 'all', 'mode', 'num_unique', 'min', 'last', \n",
    "                  'mean', 'percent_true', 'max', 'std', 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>years</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>weekday</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform Datetime feature into the boolean of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>isin</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, checks whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>seconds</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>is_null</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of base feature, return 'True' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cum_max</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the max of previous values of an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>months</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>negate</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that negates a fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cum_mean</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the mean of previous values of an i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>divide</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that divides two f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weeks</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>or</td>\n",
       "      <td>transform</td>\n",
       "      <td>For two boolean values, determine if one value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>minutes</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>second</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the second.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>not</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, negates th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>subtract</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that subtracts two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>haversine</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculate the approximate haversine distance i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>hour</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the hour.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>days_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, compute th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>day</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>latitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the first value of the tuple base feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>characters</td>\n",
       "      <td>transform</td>\n",
       "      <td>Return the characters in a given string.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>weekend</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform Datetime feature into the boolean of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>absolute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Absolute value of base feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cum_min</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the min of previous values of an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>year</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>time_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates time since the cutoff time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cum_count</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the number of previous values of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mod</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that divides two f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>month</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the month.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>cum_sum</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the sum of previous values of an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>multiply</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that multplies two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>week</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>and</td>\n",
       "      <td>transform</td>\n",
       "      <td>For two boolean values, determine if both valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>add</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that adds two feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>hours</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>diff</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the difference between the value of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>minute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the minute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>days</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>longitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the second value on the tuple base fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>numwords</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the words in a given string by countin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>percentile</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, determines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>time_since_previous</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the time since the previous instance.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name       type  \\\n",
       "19                years  transform   \n",
       "20              weekday  transform   \n",
       "21                 isin  transform   \n",
       "22              seconds  transform   \n",
       "23              is_null  transform   \n",
       "24              cum_max  transform   \n",
       "25               months  transform   \n",
       "26               negate  transform   \n",
       "27             cum_mean  transform   \n",
       "28               divide  transform   \n",
       "29                weeks  transform   \n",
       "30                   or  transform   \n",
       "31              minutes  transform   \n",
       "32               second  transform   \n",
       "33                  not  transform   \n",
       "34             subtract  transform   \n",
       "35            haversine  transform   \n",
       "36                 hour  transform   \n",
       "37           days_since  transform   \n",
       "38                  day  transform   \n",
       "39             latitude  transform   \n",
       "40           characters  transform   \n",
       "41              weekend  transform   \n",
       "42             absolute  transform   \n",
       "43              cum_min  transform   \n",
       "44                 year  transform   \n",
       "45           time_since  transform   \n",
       "46            cum_count  transform   \n",
       "47                  mod  transform   \n",
       "48                month  transform   \n",
       "49              cum_sum  transform   \n",
       "50             multiply  transform   \n",
       "51                 week  transform   \n",
       "52                  and  transform   \n",
       "53                  add  transform   \n",
       "54                hours  transform   \n",
       "55                 diff  transform   \n",
       "56               minute  transform   \n",
       "57                 days  transform   \n",
       "58            longitude  transform   \n",
       "59             numwords  transform   \n",
       "60           percentile  transform   \n",
       "61  time_since_previous  transform   \n",
       "\n",
       "                                          description  \n",
       "19  Transform a Timedelta feature into the number ...  \n",
       "20  Transform Datetime feature into the boolean of...  \n",
       "21  For each value of the base feature, checks whe...  \n",
       "22  Transform a Timedelta feature into the number ...  \n",
       "23  For each value of base feature, return 'True' ...  \n",
       "24  Calculates the max of previous values of an in...  \n",
       "25  Transform a Timedelta feature into the number ...  \n",
       "26  Creates a transform feature that negates a fea...  \n",
       "27  Calculates the mean of previous values of an i...  \n",
       "28  Creates a transform feature that divides two f...  \n",
       "29  Transform a Timedelta feature into the number ...  \n",
       "30  For two boolean values, determine if one value...  \n",
       "31  Transform a Timedelta feature into the number ...  \n",
       "32      Transform a Datetime feature into the second.  \n",
       "33  For each value of the base feature, negates th...  \n",
       "34  Creates a transform feature that subtracts two...  \n",
       "35  Calculate the approximate haversine distance i...  \n",
       "36        Transform a Datetime feature into the hour.  \n",
       "37  For each value of the base feature, compute th...  \n",
       "38         Transform a Datetime feature into the day.  \n",
       "39  Returns the first value of the tuple base feat...  \n",
       "40           Return the characters in a given string.  \n",
       "41  Transform Datetime feature into the boolean of...  \n",
       "42                    Absolute value of base feature.  \n",
       "43  Calculates the min of previous values of an in...  \n",
       "44        Transform a Datetime feature into the year.  \n",
       "45             Calculates time since the cutoff time.  \n",
       "46  Calculates the number of previous values of an...  \n",
       "47  Creates a transform feature that divides two f...  \n",
       "48       Transform a Datetime feature into the month.  \n",
       "49  Calculates the sum of previous values of an in...  \n",
       "50  Creates a transform feature that multplies two...  \n",
       "51        Transform a Datetime feature into the week.  \n",
       "52  For two boolean values, determine if both valu...  \n",
       "53  Creates a transform feature that adds two feat...  \n",
       "54  Transform a Timedelta feature into the number ...  \n",
       "55  Compute the difference between the value of a ...  \n",
       "56      Transform a Datetime feature into the minute.  \n",
       "57  Transform a Timedelta feature into the number ...  \n",
       "58  Returns the second value on the tuple base fea...  \n",
       "59  Returns the words in a given string by countin...  \n",
       "60  For each value of the base feature, determines...  \n",
       "61      Compute the time since the previous instance.  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_primitives = ['weekend', 'cum_sum', 'day', 'month', 'diff', 'time_since_previous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Primitives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_primitives = ['sum', 'count', 'mean', 'percent_true', 'all', 'any']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Synthesis with Specified Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                      cutoff_time = cutoff_times, \n",
    "                      agg_primitives = agg_primitives,\n",
    "                      trans_primitives = trans_primitives,\n",
    "                      where_primitives = where_primitives,\n",
    "                      max_depth = 2, features_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will generate 230 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'This will generate {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Deep Feature Synthesis\n",
    "\n",
    "Once we're happy with the features that will be generated, we can run deep feature synthesis to make the actual features. We need to change `feature_only` to `False` and then we're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21987"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21856"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cutoff_times)\n",
    "cutoff_times = cutoff_times.drop_duplicates()\n",
    "len(cutoff_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 230 features\n",
      "Elapsed: 07:19 | Remaining: 00:00 | Progress: 100%|| Calculated: 219/219 chunks\n",
      "441 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                                      cutoff_time = cutoff_times, \n",
    "                                      agg_primitives = agg_primitives,\n",
    "                                      trans_primitives = trans_primitives,\n",
    "                                      where_primitives = where_primitives,\n",
    "                                      max_depth = 2, features_only = False,\n",
    "                                      verbose = 1, chunk_size = 100)\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>gender</th>\n",
       "      <th>SUM(logs.num_25)</th>\n",
       "      <th>SUM(logs.num_50)</th>\n",
       "      <th>SUM(logs.num_75)</th>\n",
       "      <th>SUM(logs.num_985)</th>\n",
       "      <th>SUM(logs.num_100)</th>\n",
       "      <th>SUM(logs.num_unq)</th>\n",
       "      <th>...</th>\n",
       "      <th>WEEKEND(LAST(logs.date))</th>\n",
       "      <th>WEEKEND(LAST(transactions.transaction_date))</th>\n",
       "      <th>WEEKEND(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>DAY(LAST(logs.date))</th>\n",
       "      <th>DAY(LAST(transactions.transaction_date))</th>\n",
       "      <th>DAY(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>MONTH(LAST(logs.date))</th>\n",
       "      <th>MONTH(LAST(transactions.transaction_date))</th>\n",
       "      <th>MONTH(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=</th>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              city    bd  registered_via  \\\n",
       "msno                                                                       \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=   5.0   0.0             3.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=   4.0  23.0             9.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=  22.0   0.0             3.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=   5.0   0.0             3.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=  22.0   0.0             9.0   \n",
       "\n",
       "                                             gender  SUM(logs.num_25)  \\\n",
       "msno                                                                    \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=    NaN               1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=   male               0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=   male              27.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=    NaN               0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=    NaN               0.0   \n",
       "\n",
       "                                              SUM(logs.num_50)  \\\n",
       "msno                                                             \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=               1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=               0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=               5.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=               0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=               0.0   \n",
       "\n",
       "                                              SUM(logs.num_75)  \\\n",
       "msno                                                             \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=               0.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=               0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=               5.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=               0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=               0.0   \n",
       "\n",
       "                                              SUM(logs.num_985)  \\\n",
       "msno                                                              \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                0.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                2.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                0.0   \n",
       "\n",
       "                                              SUM(logs.num_100)  \\\n",
       "msno                                                              \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=               72.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=               78.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                0.0   \n",
       "\n",
       "                                              SUM(logs.num_unq)  ...    \\\n",
       "msno                                                             ...     \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=               64.0  ...     \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                0.0  ...     \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=               49.0  ...     \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                0.0  ...     \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                0.0  ...     \n",
       "\n",
       "                                              WEEKEND(LAST(logs.date))  \\\n",
       "msno                                                                     \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                       0.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                       0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                       0.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                       0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                       0.0   \n",
       "\n",
       "                                              WEEKEND(LAST(transactions.transaction_date))  \\\n",
       "msno                                                                                         \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                           0.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                           0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                           0.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                           0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                           0.0   \n",
       "\n",
       "                                              WEEKEND(LAST(transactions.membership_expire_date))  \\\n",
       "msno                                                                                               \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                                1.0    \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                                1.0    \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                                1.0    \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                                1.0    \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                                1.0    \n",
       "\n",
       "                                              DAY(LAST(logs.date))  \\\n",
       "msno                                                                 \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                   1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                   NaN   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                   1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                   NaN   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                   NaN   \n",
       "\n",
       "                                              DAY(LAST(transactions.transaction_date))  \\\n",
       "msno                                                                                     \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                       1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                       1.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                       1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                       1.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                       1.0   \n",
       "\n",
       "                                              DAY(LAST(transactions.membership_expire_date))  \\\n",
       "msno                                                                                           \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                            31.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                             1.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                             1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                             1.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                             1.0   \n",
       "\n",
       "                                              MONTH(LAST(logs.date))  \\\n",
       "msno                                                                   \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                     1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                     NaN   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                     1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                     NaN   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                     NaN   \n",
       "\n",
       "                                              MONTH(LAST(transactions.transaction_date))  \\\n",
       "msno                                                                                       \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                         1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                         1.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                         1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                         1.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                         1.0   \n",
       "\n",
       "                                              MONTH(LAST(transactions.membership_expire_date))  \\\n",
       "msno                                                                                             \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                               1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                               2.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                               2.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                               2.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                               2.0   \n",
       "\n",
       "                                              label  \n",
       "msno                                                 \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=    0.0  \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=    0.0  \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=    0.0  \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=    NaN  \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=    0.0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    18861\n",
       "1.0      603\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_times['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_matrix = feature_matrix[feature_matrix['label'].notnull()].copy()\n",
    "labels = np.array(feature_matrix.pop('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_matrix = pd.get_dummies(feature_matrix).replace({np.inf: np.nan, -np.inf:np.nan}).fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, labels, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9767776407727086"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 1000, max_depth = 10)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689683518290176"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_defs, '/data/churn/features.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition to Feature Matrix\n",
    "\n",
    "Now we'll write a function that takes in the partition number and outputs a feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 230 features.\n"
     ]
    }
   ],
   "source": [
    "feature_defs = ft.load_features('/data/churn/features.txt')\n",
    "print(f'There are {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_to_feature_matrix(partition, feature_defs):\n",
    "    \"\"\"Take in a partition number and return a feature matrix\"\"\"\n",
    "    directory = '/data/churn/partitions/p' + PARTITION\n",
    "    \n",
    "    # Read in the data files\n",
    "    members = pd.read_csv(f'{directory}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], \n",
    "                      infer_datetime_format = True, \n",
    "                      dtype = {'gender': 'category'})\n",
    "\n",
    "    trans = pd.read_csv(f'{directory}/transactions.csv',\n",
    "                       parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                        infer_datetime_format = True)\n",
    "\n",
    "    logs = pd.read_csv(f'{directory}/logs.csv', parse_dates = ['date'])\n",
    "    cutoff_times = pd.read_csv(f'{directory}/cutoff_times.csv', parse_dates = ['cutoff'])\n",
    "    cutoff_times = cutoff_times.drop_duplicates()\n",
    "    \n",
    "    # Create empty entityset\n",
    "    es = ft.EntitySet(id = 'customers')\n",
    "\n",
    "    # Add the members parent table\n",
    "    es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                             index = 'msno', time_index = 'registration_init_time', \n",
    "                             variable_types = {'city': vtypes.Categorical, 'bd': vtypes.Categorical,\n",
    "                                               'registered_via': vtypes.Categorical})\n",
    "    # Create new features in transactions\n",
    "    trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "    trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "    trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']\n",
    "\n",
    "    # Add the transactions child table\n",
    "    es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                             index = 'transactions_index', make_index = True,\n",
    "                             time_index = 'transaction_date', \n",
    "                             variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                               'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})\n",
    "\n",
    "    # Add transactions interesting values\n",
    "    es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "    es['transactions']['is_auto_renew'].interesting_values = [0, 1]\n",
    "    \n",
    "    # Create new features in logs\n",
    "    logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "    logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "    logs['percent_unique'] = logs['num_unq'] / logs['total']\n",
    "    \n",
    "    # Add the logs child table\n",
    "    es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')\n",
    "\n",
    "    # Add the relationships\n",
    "    r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "    r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "    es.add_relationships([r_member_transactions, r_member_logs])\n",
    "\n",
    "    # Calculate and save the feature matrix\n",
    "    feature_matrix = ft.calculate_feature_matrix(entityset=es, features=feature_defs, cutoff_time=cutoff_times)\n",
    "    \n",
    "    feature_matrix.to_csv(f'{directory}/feature_matrix.csv')\n",
    "    \n",
    "    # Report progress every 10th of number of partitions\n",
    "    if (partition % (N_PARTITIONS / 10) == 0):\n",
    "        print(f'{100 * round(partition / N_PARTITIONS)}% complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many levels: Index has only 1 level, not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-bece5a2d22dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition_to_feature_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_defs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-177-ec30369954c2>\u001b[0m in \u001b[0;36mpartition_to_feature_matrix\u001b[0;34m(partition, feature_defs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Calculate and save the feature matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_feature_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{directory}/feature_matrix.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, entityset, cutoff_time, instance_ids, entities, relationships, cutoff_time_in_index, training_window, approximate, save_progress, verbose, chunk_size, n_jobs, dask_kwargs, profile)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                                  \u001b[0mcutoff_df_time_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_df_time_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                                  \u001b[0mtarget_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                                                  pass_columns=pass_columns)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mlinear_calculate_chunks\u001b[0;34m(chunks, features, approximate, training_window, profile, verbose, save_progress, entityset, no_unapproximated_aggs, cutoff_df_time_var, target_time, pass_columns)\u001b[0m\n\u001b[1;32m    518\u001b[0m                                           \u001b[0mcutoff_df_time_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                                           \u001b[0mtarget_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                                           backend=backend)\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_feature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# Do a manual garbage collection in case objects from calculate_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_chunk\u001b[0;34m(chunk, features, approximate, training_window, profile, verbose, save_progress, no_unapproximated_aggs, cutoff_df_time_var, target_time, pass_columns, backend, entityset)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                            \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                            \u001b[0mprecalculated_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecalculated_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                            training_window=window)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mid_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_feature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_progress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pydatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalc_results\u001b[0;34m(time_last, ids, precalculated_features, training_window)\u001b[0m\n\u001b[1;32m    314\u001b[0m                                                     \u001b[0mprecalculated_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecalculated_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                                                     \u001b[0mignored\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_approx_feature_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                                     profile=profile)\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/pandas_backend.py\u001b[0m in \u001b[0;36mcalculate_all_features\u001b[0;34m(self, instance_ids, time_last, training_window, profile, precalculated_features, ignored, verbose)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_type_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mresult_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0moutput_frames_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_frames_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/pandas_backend.py\u001b[0m in \u001b[0;36m_calculate_agg_features\u001b[0;34m(self, features, entity_frames)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mto_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroupby_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mto_merge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             frame = pd.merge(left=frame, right=to_merge,\n\u001b[1;32m    444\u001b[0m                              \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   4099\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4100\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4101\u001b[0;31m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4099\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4100\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4101\u001b[0;31m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_index_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_index_level\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                 raise IndexError(\"Too many levels:\"\n\u001b[1;32m   1954\u001b[0m                                  \u001b[0;34m\" Index has only 1 level, not %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                                  (level + 1))\n\u001b[0m\u001b[1;32m   1956\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             raise KeyError('Level %s must be same as name (%s)' %\n",
      "\u001b[0;31mIndexError\u001b[0m: Too many levels: Index has only 1 level, not 2"
     ]
    }
   ],
   "source": [
    "feature_matrix = partition_to_feature_matrix(100, feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
